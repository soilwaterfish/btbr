[{"path":"https://github.com/soilwaterfish/aisrisk/articles/final_scores.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Final Scores","text":"report covers methods used generate Aquatic Invasive Species (AIS) prioritization Idaho specifically Nez-Perce/Clearwater Idaho Panhandle National Forests. used methods described Montana Fish, Wildlife Parks AIS prioritization lotic lentic environments best . input data difficult retrieve due lack collection various unorganized sources, thus data gaps likely help final results.","code":""},{"path":"https://github.com/soilwaterfish/aisrisk/articles/final_scores.html","id":"final-scores","dir":"Articles","previous_headings":"","what":"Final Scores","title":"Final Scores","text":"final score calculations done adding together social habitat scores fitting refined scoring matrix. forces scores 1 (highest risk) 10 (least risk). ’ll notice scores 1, 2, 5 can attributed lack data available habitat suitability metrics (1 2) well 5 peculiar scoring designation (data either habitat social), doesn’t happen case. final designations;","code":""},{"path":"https://github.com/soilwaterfish/aisrisk/articles/final_scores.html","id":"social-suitability-score","dir":"Articles","previous_headings":"","what":"Social Suitability Score","title":"Final Scores","text":"Social Suitability Score broken 5 different indicators potential invasion risk via social proxies. factors stratified categories 1-4 based different thresholds (see Tables ). scores used final risk score adding Habitat Suitability Score.  Waterbody Type - simply breaking waters risk large lakes risk small streams less risk. Waterbody Size - surrogate recreation based idea longer river larger lake typically see recreational use. Position Watershed - Position watershed highlights areas lower watershed typically going risk AIS due accessibility downstream waterways. Mussel Proximity - distance nearest invasive mussel populations via road network. Angler Days - days anglers fishing higher days mean higher risk. Waterbody Type Waterbody Size Position Watershed Mussel Proximity Angler Days         Still need figure angler days.","code":""},{"path":"https://github.com/soilwaterfish/aisrisk/articles/final_scores.html","id":"habitat-suitability-score","dir":"Articles","previous_headings":"","what":"Habitat Suitability Score","title":"Final Scores","text":"Habitat Suitability Score broken 6 different indicators potential risk invasion via physical conditions. factors stratified categories 1-4 based different thresholds (see Tables ). scores used final risk score adding Social Suitability Score. note, large data gap variables (calcium, dissolved oxygen, hardness), likely effect overall score since missing data. data gap leads low score, might , structurally biased since scores additive.  Water Temperature - breaks water different levels risk based temperature. pH - surrogate recreation based idea longer river larger lake typically see recreational use. Hardness - Position watershed highlights areas lower watershed typically going risk AIS due accessibility downstream waterways. Calcium - distance nearest invasive mussel populations via road network. Conductivity - days anglers fishing higher days mean higher risk. Dissolved Oxygen - days anglers fishing higher days mean higher risk.  Water Temperature pH Hardness Calcium Conductivity Dissolved Oxygen","code":""},{"path":"https://github.com/soilwaterfish/aisrisk/articles/hss.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Habitat Suitability Score Criteria - GIS ","text":"GIS workflow covers habitat suitability methods used generate Aquatic Invasive Species (AIS) prioritization Idaho specifically Nez-Perce/Clearwater Idaho Panhandle National Forests. used methods described Montana Fish, Wildlife Parks AIS prioritization lotic lentic environments best . vignette, steps take time process (~mins) can take decent amount memory (> 1 Gb) please warned running code . Getting specific data model difficult due various metrics, sources collection history. lead lot areas lacking data (see Figure ) affecting final model output. Eventually, idea bring Bayesian analysis framework help scattered data. now, just stay existing framework. , goal vignette show steps took get figure output . Final habitat scores six metrics. Notice lot missing data certain metrics.","code":""},{"path":"https://github.com/soilwaterfish/aisrisk/articles/hss.html","id":"data","dir":"Articles","previous_headings":"Overview","what":"Data","title":"Habitat Suitability Score Criteria - GIS ","text":"data retrieval part model intensive requires webscraping http retrieval skills. three main sources going get data ; (NorWest Stream Temperature)[https://www.fs.usda.gov/rm/boise/AWAE/projects/NorWeST.html]. (Water Quality Portal (WQP))[https://www.waterqualitydata.us/]. (Beneficial Use Reconnaissance Program (BURP))[https://www2.deq.idaho.gov/water/BurpViewer/]. ’ll go step getting data bringing together end. ’ll also need nhdplus_idaho_final_social waterbody_idaho_final_social data social vignette end join together.","code":""},{"path":"https://github.com/soilwaterfish/aisrisk/articles/hss.html","id":"stream-temperature","dir":"Articles","previous_headings":"Overview","what":"Stream Temperature","title":"Habitat Suitability Score Criteria - GIS ","text":"get stream temperature data ’ll use NorWest modelled stream temperature data August (Isaak et al., 2017). ’ll get via {fishguts} package select appropriate watersheds, information see ?fishguts::get_NorWestStreams. ’s nice dataset ’s linked dataset (nhdplus_idaho) comid. Since isn’t stream temperature associated NorWest Streams dataset waterbodies tried get WQP BURP; however, wasn’t water temperature associated waterbodies. water temperature data collected AIS monitoring previous years used data fill gap within waterbodies best .","code":"library(sf) library(tidyverse)  #### bring in water temp from NorWest  spokoot <- fishguts::get_NorWestStreams('SpoKoot')  cwb <- fishguts::get_NorWestStreams('Clearwater River Basin')  srb <- fishguts::get_NorWestStreams('Salmon River Basin')  middle_columbia <- fishguts::get_NorWestStreams('Middle Columbia')  idaho <- AOI::aoi_get(state = 'idaho')  stream_temp_id <- bind_rows(st_as_sf(spokoot), st_as_sf(cwb), st_as_sf(srb), st_as_sf(middle_columbia))  stream_temp_id <- stream_temp_id %>% st_as_sf() %>% st_intersection(st_transform(idaho, st_crs(stream_temp_id))) #### create an empty list to put previous years data into   monitorings_sites_quagga_zebra <- list()   library(arcgis) # loop through and call ESRI api for (i in c(1:8)){  monitorings_sites_quagga_zebra[[i]] <- arc_select(arc_open(paste0('https://gis.psmfc.org/server/rest/services/WesternAIS/Quagga_and_Zebra_Mussel_Monitoring_Sites/MapServer/', i)))   }  # clean up weird character geometries monitorings_sites_quagga_zebra_sf <- bind_rows(monitorings_sites_quagga_zebra) %>% st_as_sf()  monitorings_sites_quagga_zebra_sf$geom_char <- map(st_geometry(monitorings_sites_quagga_zebra_sf), ~is.numeric(.x[[1]])) %>%                                                 unlist()  monitorings_sites_quagga_zebra_sf <- monitorings_sites_quagga_zebra_sf %>% filter(geom_char)   monitorings_sites_quagga_zebra_sf <- monitorings_sites_quagga_zebra_sf[!st_is_empty(st_zm(monitorings_sites_quagga_zebra_sf)),,drop=FALSE]  # filter and clean up  ais_list <- monitorings_sites_quagga_zebra_sf %>% st_intersects(st_transform(idaho, st_crs(monitorings_sites_quagga_zebra_sf)))  ais_list <- lengths(ais_list) > 0  # now we'll have each site within idaho  monitorings_sites_quagga_zebra_sf <- monitorings_sites_quagga_zebra_sf[ais_list,]   # you could really try and get as much as you can but  # for our area the water temp is the most robust so we'll stick with that  # clean up  monitorings_sites_quagga_zebra_sf <- monitorings_sites_quagga_zebra_sf %>%                                       filter(!is.na(WATERTEMPF)) %>%                                       select(temperature_water = 'WATERTEMPF')"},{"path":"https://github.com/soilwaterfish/aisrisk/articles/hss.html","id":"water-quality-portal","dir":"Articles","previous_headings":"Overview","what":"Water Quality Portal","title":"Habitat Suitability Score Criteria - GIS ","text":"’ll need access WQP data get rest scores. ’d recommend sort query call API download via website. way using {dataRetrieval} package. take download also take decent amount space (> Gb) aware running! move BURP data retrieval, ’ll clean WQP data remove unwanted locations.","code":"# we'll use these characteristic names to query the WQP  wq_names <- c(                 \"pH\", \"Bicarbonate\",                                                               \"Calcium\", \"Calcium carbonate\",                                                       \"Hardness, Ca, Mg\", \"Dissolved oxygen saturation\",                                                 \"Dissolved oxygen (DO)\", \"Conductivity\",                                                                \"Hardness, non-carbonate\", \"Alkalinity, carbonate\" ,                                                      \"Alkalinity, bicarbonate\", \"Hardness, magnesium\" ,                                                        \"Hardness, carbonate\", \"Total hardness\",                                                              \"Alkalinity, Phenolphthalein (total hydroxide+1/2 carbonate)\", \"Specific conductivity\",                                                       \"Hardness\", \"Calcium as CaCO3\" ,                                                           \"Alkalinity, Bicarbonate as CaCO3\"                 )  # Also, keep it to Idaho and within water. wqp_idaho <- dataRetrieval::readWQPdata(statecode = 'ID',                                         characteristicName = wq_names,                                         sampleMedia = 'Water')  ### we'll use this to intersect the huc12s and waterbodies  wqp_idaho_site_info <- attr(wqp_idaho, 'siteInfo')  wqp_idaho_sf <- st_as_sf(wqp_idaho_site_info %>% filter(!is.na(dec_lon_va)), coords = c('dec_lon_va', 'dec_lat_va'), crs = 4326)  # now combined with HUCS to make easier.  huc12 <- read_sf('data/simple_features.gpkg', layer = 'huc12')  huc_list <- st_intersects(wqp_idaho_sf, st_transform(huc12, crs = st_crs(wqp_idaho_sf)))  huc_list <- map_vec(huc_list, ~ifelse(is.null(.x), NA, .x))  # now we'll have each site iwth a huc12   wqp_idaho_sf$huc12 <- huc12[huc_list,]$huc12 wqp_idaho_filtered <-   wqp_idaho %>%                          filter(ResultSampleFractionText  %in% c('Total', 'Filtered, lab'),                                ActivityMediaSubdivisionName == \"Surface Water\") %>%                         mutate(ResultMeasureValue = readr::parse_number(ResultMeasureValue),                                ResultMeasureValue  = if_else(ResultMeasure.MeasureUnitCode  %in% c('ug/L', 'ug/l'),                                                              ResultMeasureValue*0.001, ResultMeasureValue),                                ResultMeasure.MeasureUnitCode = if_else(ResultMeasure.MeasureUnitCode  %in% c('ug/L', 'ug/l'),                                                                        'mg/L',ResultMeasure.MeasureUnitCode)) %>%                         janitor::clean_names() %>%                          tibble()%>%                         mutate(date = lubridate::date(activity_start_date_time)) %>%                          group_by(monitoring_location_identifier, date) %>%                          mutate(result_measure_value = mean(result_measure_value, na.rm = T)) %>%                          slice(1) %>%                          ungroup()  # now add the huc12 id to join later with BURP, etc  wqp_idaho_filtered <- wqp_idaho_filtered %>%                        left_join(wqp_idaho_sf %>% st_drop_geometry() %>%                                  select(huc12,monitoring_location_identifier = 'MonitoringLocationIdentifier'))"},{"path":"https://github.com/soilwaterfish/aisrisk/articles/hss.html","id":"burp","dir":"Articles","previous_headings":"Overview","what":"BURP","title":"Habitat Suitability Score Criteria - GIS ","text":"hacky-way get bunch data website might possible otherwise. first step get site ids BURP data. Step 2: create function scrape html website lists table per site per year. Step 3: run function parallel crawl webpage.","code":"library(httr2) library(tidyverse)  #### Now try and get the BURP data site_ids <- vector()  for(i in c(1994:2008, 2010:2023)) {        url_sites <- paste0('https://www2.deq.idaho.gov/water/BurpViewer/Menu?Year=', i)        req <- request(url_sites)        req_body <- req %>% req_perform()        # get ids       ids <- readLines(req_body$url)        keywords <- paste0(i,\"[A-Z0-9]+\")        si <- na.omit(str_extract(ids, keywords))        site_ids <- append(site_ids, si)   }  # get the ids  site_ids_filtered <- str_unique(site_ids) # get info from ids  burp_func <- function(id){        url_streams <- paste0('https://www2.deq.idaho.gov/water/BurpViewer/BurpSite/Stream?BurpID=', id)        req <- request(url_streams)        req_body <- req %>% req_perform()        stream_html <- req_body %>% resp_body_html()        values <- stream_html %>%       rvest::html_elements(xpath = \"//span[@class='readOnly']/text()\") %>%       rvest::html_text2()        labels <- stream_html %>%         rvest::html_elements(xpath = \"//div[@class='oneThird']/label/text()\") %>%         rvest::html_text2()        meta_label <- stream_html %>%         rvest::html_elements(xpath = \"//div[@id='leftCol']//ul/li/text()\") %>%         rvest::html_text2()        meta <- stream_html %>%         rvest::html_elements(xpath = \"//div[@id='leftCol']//ul/li/strong/text()\") %>%         rvest::html_text2()        meta <- stream_html %>%         rvest::html_elements(xpath = \"//div[@id='leftCol']//ul/li/strong/text()\") %>%         rvest::html_text2()        md <- tibble(         labels = meta_label[-2],         value = meta       )        url_location <- paste0('https://www2.deq.idaho.gov/water/BurpViewer/BurpSite/Location?BurpID=', id)        req <- request(url_location)        req_body <- req %>% req_perform()        location_html <- req_body %>% resp_body_html()        values_loc <- location_html %>%         rvest::html_elements(xpath = \"//div[@class='half']//label/text()\") %>%         rvest::html_text2()        labels_loc <- location_html %>%         rvest::html_elements(xpath = \"//span[@class='readOnly']/text()\") %>%         rvest::html_text2()        site_info <- tibble(labels = labels,                           values = values,                           sample_year = md[2,2]$value,                           stream = md[3,2]$value,                           assessment_unit = md[4,2]$value,                           site_id = id)%>%         pivot_wider(names_from = labels, values_from = values) %>%         janitor::clean_names()        location_info <- tibble(labels = labels_loc,                           values = values_loc,                           site_id = id) %>%                         pivot_wider(names_from = values, values_from = labels) %>%                         janitor::clean_names()        left_join(site_info, location_info)  } library(future) plan(multisession(workers = availableCores()-1))  test <- site_ids_filtered %>%         furrr::future_map(purrr::safely(~burp_func(.)))  burp_final <- test %>%   purrr::keep(~length(.) != 0) %>%   purrr::map(~.x[['result']]) %>%   plyr::rbind.fill()  #### now clean up and make a spatial copy  burp_final_cleaned <- burp_final %>%   mutate(across(everything(), ~ifelse(.x  %in% c('No Data', 'NA m', ' ', '', 'mg/l'), NA_real_, .x))) %>%   mutate(across(c(air_temperature:total_reach_length, stream_order), ~parse_number(.x))) %>%   filter(latitude > 0,          site_id != '2001SPOCA029',          p_h < 15,          p_h > 0)  burp_final_cleaned_sf <- burp_final_cleaned %>% sf::st_as_sf(coords = c('longitude', 'latitude'), crs = 4326)  #now intersect with huc12  huc_list <- st_intersects(burp_final_cleaned_sf, st_transform(huc12, crs = st_crs(burp_final_cleaned_sf)))  huc_list <- map_vec(huc_list, ~ifelse(is.null(.x), NA, .x))  # now we'll have each site iwth a huc12   burp_final_cleaned_sf$huc12 <- huc12[huc_list,]$huc12  # write if need be...  # write_csv(burp_final_cleaned, 'data/burp_sites_cleaned_1994-2023.csv') # write_sf(burp_final_cleaned_sf, 'data/simple_features.gpkg', layer = 'burp_final_cleaned_sf')"},{"path":"https://github.com/soilwaterfish/aisrisk/articles/hss.html","id":"bring-it-all-together","dir":"Articles","previous_headings":"Overview","what":"Bring it all together","title":"Habitat Suitability Score Criteria - GIS ","text":"Finally! can now start bring together. ’ll start notice lot output NA. due lack data across domain water quality measurements. counted current model future model might look sort regularization prior help missing data. need now calculate stream temperature cutoffs bring everything back waterbodies flowlines. Bring previously created datasets nhdplus_idaho_final_social waterbodies_idaho_final_social.","code":"wqp_idaho_filtered_summarized <- wqp_idaho_filtered %>%                                   select(characteristic_name, result_measure_value,                                         monitoring_location_identifier, huc12,                                          date) %>%                                   pivot_wider(names_from = 'characteristic_name',                                              values_from = 'result_measure_value') %>%                                   janitor::clean_names() %>%                                   group_by(huc12) %>%                                   summarise(across(p_h:hardness_non_carbonate, ~mean(.x, na.rm = TRUE))) %>%                                   select(huc12,                                         p_h,                                         calcium,                                         conductivity,                                         temperature_water,                                         hardness = 'hardness_ca_mg',                                          dissolved_oxygen = 'dissolved_oxygen_do')                                   # now do the same with the BURP data  burp_final_cleaned_summarized <- burp_final_cleaned_sf %>%                                   st_drop_geometry() %>%                                   select(huc12, conductivity:dissolved_oxygen) %>%                                   group_by(huc12) %>%                                   summarise(across(conductivity:dissolved_oxygen, ~mean(.x, na.rm = TRUE)))                                                                     # now bind together and group summarize by huc12  all_together_burp_wqp <- bind_rows(wqp_idaho_filtered_summarized, burp_final_cleaned_summarized) %>%                     group_by(huc12) %>%                     summarise(across(everything(), ~mean(.x, na.rm = TRUE)))  # now we can do a long if/else  final_ish_model <- all_together_burp_wqp %>%   mutate(     p_h_model = case_when(     p_h > 0 & p_h <= 3.9 ~ 1,     p_h > 4 & p_h <= 5.4~ 2,     p_h > 5.5 & p_h <= 6.9 ~ 3,     p_h > 7 & p_h <= 9.9 ~ 4,     p_h > 10 & p_h <= 11 ~ 3,     p_h > 11 & p_h <= 13 ~ 2,     p_h > 13 & p_h <= 14 ~ 1,     TRUE ~ NA   ),     calcium_model = case_when(     calcium > 0 & calcium <= 4 ~ 1,     calcium > 4 & calcium <= 13~ 2,     calcium > 13 & calcium <= 24 ~ 3,     calcium > 24 & calcium <= 100 ~ 4,     TRUE ~ NA   ),     hardness_model = case_when(     hardness > 0 & hardness <= 50 ~ 1,     hardness > 50 & hardness <= 99~ 2,     hardness > 99 & hardness <= 125 ~ 3,     hardness > 125 & hardness <= 1000 ~ 4,     TRUE ~ NA   ),     do_model = case_when(     dissolved_oxygen > 0 & dissolved_oxygen <= 3 ~ 1,     dissolved_oxygen > 3 & dissolved_oxygen <= 7~ 2,     dissolved_oxygen > 7 & dissolved_oxygen <= 12 ~ 3,     dissolved_oxygen > 12 & dissolved_oxygen <= 50 ~ 4,     TRUE ~ NA   ),     conductivity_model = case_when(     conductivity > 0 & conductivity <= 490 ~ 1,     conductivity > 490 & conductivity <= 989~ 2,     conductivity > 989 & conductivity <= 1499 ~ 3,     conductivity > 1499 & conductivity <= 3000 ~ 4,     TRUE ~ NA   )   ) stream_temp_id <- stream_temp_id %>%      rename(temperature_water = 'S2_02_11') %>%      mutate(     temperature_water = (temperature_water*9/5) + 32,      temperature_model = case_when(       temperature_water > 0 & temperature_water <= 40 ~ 1,       temperature_water > 40 & temperature_water <= 46~ 2,       temperature_water > 46& temperature_water <= 56 ~ 3,       temperature_water > 56 & temperature_water <= 71 ~ 4,       temperature_water > 71 & temperature_water <= 75 ~ 3,       temperature_water > 75 & temperature_water <= 83 ~ 2,       temperature_water > 83 & temperature_water <= 120 ~ 1,       TRUE ~ NA     )) %>%      st_drop_geometry() %>%      select(comid = 'COMID', temperature = 'temperature_water', temperature_model) nhdplus_idaho <- read_sf('data/simple_features.gpkg', layer = 'nhdplus_idaho_final_social')  waterbodies_idaho <- read_sf('data/simple_features.gpkg', layer = 'waterbodies_idaho_final_social')  nhdplus_idaho_final_together <- nhdplus_idaho %>% select(comid, huc12, starts_with('waterbody_'), mussel_proximity) %>%                                  left_join(final_ish_model) %>%                                  left_join(stream_temp_id %>% select(comid, temperature, temperature_model))   # now for the special case waterbodies # bc NA's for all stream_temp_id  wb_temp_list <- monitorings_sites_quagga_zebra_sf %>% st_intersects(st_transform(waterbodies_idaho, st_crs(.)))  wb_temp_list <- lengths(wb_temp_list) > 0  stream_temp_wb <- monitorings_sites_quagga_zebra_sf[wb_temp_list,]  stream_temp_wb <- stream_temp_wb %>% st_intersection(st_transform(waterbodies_idaho, st_crs(.)))   stream_temp_wb <- stream_temp_wb %>%      mutate(temperature_water = if_else(temperature_water < 32, (temperature_water*9/5) + 32, temperature_water)) %>%      group_by(comid) %>%      mutate(temperature_water = mean(temperature_water, na.rm = TRUE)) %>%      slice(1) %>%      ungroup() %>%      mutate(      temperature_model = case_when(       temperature_water > 0 & temperature_water <= 40 ~ 1,       temperature_water > 40 & temperature_water <= 46~ 2,       temperature_water > 46& temperature_water <= 56 ~ 3,       temperature_water > 56 & temperature_water <= 71 ~ 4,       temperature_water > 71 & temperature_water <= 75 ~ 3,       temperature_water > 75 & temperature_water <= 83 ~ 2,       temperature_water > 83 & temperature_water <= 120 ~ 1,       TRUE ~ NA     )) %>%      st_drop_geometry() %>%      select(comid, temperature = 'temperature_water', temperature_model)  waterbodies_idaho_final_together <- waterbodies_idaho %>% select(comid, huc12, starts_with('waterbody_'), mussel_proximity) %>%                                      left_join(final_ish_model) %>%                                      left_join(stream_temp_wb)  write_sf(nhdplus_idaho_final_together, 'data/simple_features.gpkg', layer = 'nhdplus_idaho_final_together', delete_layer = TRUE)  write_sf(waterbodies_idaho_final_together, 'data/simple_features.gpkg', layer = 'waterbodies_idaho_final_together', delete_layer = TRUE)"},{"path":"https://github.com/soilwaterfish/aisrisk/articles/hss.html","id":"references","dir":"Articles","previous_headings":"Overview","what":"References","title":"Habitat Suitability Score Criteria - GIS ","text":"Isaak DJ, Wenger SJ, Peterson EE, Ver Hoef JM, Nagel DE, Luce CH, Hostetler SW, Dunham JB, Roper BB, Wollrab SP, others (2017). “NorWeST summer stream temperature model scenarios western US: crowd-sourced database new geospatial tools foster user community predict broad climate warming rivers streams.” Water Resources Research, 53(11), 9181–9205.","code":""},{"path":"https://github.com/soilwaterfish/aisrisk/articles/sssc.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Social Suitability Score Criteria - GIS ","text":"GIS workflow covers social suitability methods used generate Aquatic Invasive Species (AIS) prioritization Idaho specifically Nez-Perce/Clearwater Idaho Panhandle National Forests. used methods described Montana Fish, Wildlife Parks AIS prioritization lotic lentic environments best .","code":""},{"path":"https://github.com/soilwaterfish/aisrisk/articles/sssc.html","id":"methods","dir":"Articles","previous_headings":"Overview","what":"Methods","title":"Social Suitability Score Criteria - GIS ","text":"methods used generate social suitability scores involve GIS processing R /Python (eventually implementing). challenging part necessarily geospatial analysis instead getting data work relate together, e.g. waterbodies streams/rivers. first part vignette go logic used waterbody type, size, position link together using Hydrological Unit Codes (HUC) National Hydrography Dataset Plus Version 2 (NHDPlus V2). follow mussel proximity workflow using road network find far away recently (2023, Snake River near Twin Falls, Idaho) found mussel population waterbodies streams/rivers. angler data proxy variable right now left analysis. goal vignette show steps took get figure output . Final social scores 4 metrics.","code":""},{"path":"https://github.com/soilwaterfish/aisrisk/articles/sssc.html","id":"data","dir":"Articles","previous_headings":"Overview > Methods","what":"Data","title":"Social Suitability Score Criteria - GIS ","text":"’ll need waterbodies, flowlines HUC 12’s Idaho via NDHPLus V2. can retrieved various sources retrieved via nhdplusTools package R. waterbodies flowlines contain two different geometry types: POLYLINE (flowlines) MULTIPOLYGON (waterbodies). aware bringing together end final score things done certain ways.","code":""},{"path":"https://github.com/soilwaterfish/aisrisk/articles/sssc.html","id":"waterbody-type","dir":"Articles","previous_headings":"Overview > Methods","what":"Waterbody Type","title":"Social Suitability Score Criteria - GIS ","text":"Waterbody type calculated using NHDPlus dataset associated attribute streamorder (Strahler) streams rivers acreage waterbodies.","code":"library(sf) library(tidyverse)  #### waterbodies_idaho and nhdplus_idaho are datasets retrieved prior to doing calculations....  waterbodies_idaho <- read_sf('data/simple_features.gpkg', layer = 'waterbodies_idaho') nhdplus_idaho <- read_sf('data/simple_features.gpkg', layer = 'nhdplus_idaho')   waterbodies_idaho <- waterbodies_idaho %>%                        mutate(area_acres = as.numeric(units::set_units(sf::st_area(.), 'acres')),                              waterbody_type = if_else(area_acres<25, 3, 4)                               )  nhdplus_idaho <- nhdplus_idaho %>%                       mutate(waterbody_type = if_else(streamorde <= 3,1,                                                  if_else(streamorde >3 & streamorde <=5 , 2, 4)))"},{"path":"https://github.com/soilwaterfish/aisrisk/articles/sssc.html","id":"waterbody-size","dir":"Articles","previous_headings":"Overview > Methods","what":"Waterbody Size","title":"Social Suitability Score Criteria - GIS ","text":"Waterbody size used proxy recreation idea larger waterbodies rivers attract use. ’ll use datasets used Waterbody Type, calculate qts quartiles waterbody part group flowlines name get lengths. Get quartiles waterbodies. Get length flowlines based gnis_name; meaning flowlines names connected length.","code":"### waterbody size  qts <- quantile(waterbodies_idaho$area_acres)  waterbodies_idaho <- waterbodies_idaho %>% mutate(waterbody_size_rec = if_else(area_acres < qts[[2]], 1,                                                                       if_else(area_acres >= qts[[2]] & area_acres < qts[[3]], 2,                                                                               if_else(area_acres >= qts[[3]] & area_acres < qts[[4]], 3, 4))))  nhdplus_idaho <- nhdplus_idaho %>%                   rowwise() %>%                   mutate(gnis_name = if_else(gnis_name == ' ', as.character(paste0(paste0(sample(letters, 4), collapse = ''), '_', sample(1:100000000, 1))), gnis_name)) %>%                   group_by(gnis_name) %>%                   mutate(dist = sum(lengthkm)) %>%                   ungroup() %>%                   mutate(waterbody_size_rec = if_else(dist < 15, 1,                                                       if_else(dist >= 15 & dist < 30, 2,                                                               if_else(dist >= 30 & dist < 60, 3, 4))))"},{"path":"https://github.com/soilwaterfish/aisrisk/articles/sssc.html","id":"waterbody-position","dir":"Articles","previous_headings":"Overview > Methods","what":"Waterbody Position","title":"Social Suitability Score Criteria - GIS ","text":"Waterbody position little trickier waterbodies (lakes) flowlines. really isn’t great way differentiate two besides elevation, fully populated waterbodies dataset. account mountain lake reservoir (score 3), just took elevation waterbodies centroid available andand value larger lake likely lowland. definitely perfect, works .","code":"# from visual inspection we can see that lakes with > 300 acres are likely lowland waterbodies  waterbodies_idaho <- waterbodies_idaho %>%                          mutate(waterbody_position = if_else(area_acres > 300, 4, NA_real_))  # now get elevations for the ones that are below 300  waterbodies_idaho_filtered <- waterbodies_idaho %>%                              filter(is.na(waterbody_position)) %>%                              st_centroid() %>%                             select(-elevation) %>%                             elevatr::get_elev_point()  waterbodies_idaho_filtered <- bind_cols( waterbodies_idaho %>% filter(is.na(waterbody_position)) %>%                                           select(id, comid) %>% st_drop_geometry(),                                          waterbodies_idaho_filtered %>% select(ele = 'elevation') %>%                                           st_drop_geometry())  # then join back with original  ### just visually looked at the patterns and most valleys are below 1600 and high mountain lake are above  waterbodies_idaho <- waterbodies_idaho %>%                       left_join(waterbodies_idaho_filtered) %>%                       mutate(waterbody_position = ifelse(!is.na(waterbody_position), waterbody_position,                                                          ifelse(ele > 1500, 3, 4)))  nhdplus_idaho <- nhdplus_idaho %>%   mutate(waterbody_position = if_else(streamorde <= 2, 1,                                       if_else(streamorde > 2 & streamorde <=3, 2,                                           if_else(streamorde > 3 & streamorde <=5 , 3, 4))))"},{"path":"https://github.com/soilwaterfish/aisrisk/articles/sssc.html","id":"mussel-proximity","dir":"Articles","previous_headings":"Overview > Methods","what":"Mussel Proximity","title":"Social Suitability Score Criteria - GIS ","text":"Mussel proximity involves calculating distance via roadways nearest mussel population. Idaho Snake River near Twin Falls change updating important. workflow used create road network calculate cost distance affected area. First ’ll need roadnetwork cleaned. mean clean network multiples, loops, missing vertices crossing lines. ways ’d recommend using planarize tool ArcPro able quickly (need find R alternative). clean network, can start getting distances affected area (mussel_point). Depending CRS projection ’ll want adjust distances also final metric, miles case. Now network roads shortest path mussel location.  way link road network distances mussel_point find closest waterbody snap together. precise accurate way heavily intensive likely gaining much insight, .e. dealing miles. Thus, ’ll take HUC 12 road intersects use surrogate distance taking mean distances. can join back original datasets waterbodies_idaho nhdplus_idaho. help HUC 12 linked datasets distance also suitability score habitat. ’s perfect ’s flaws efficient way getting indicator score. Another issue getting road data can difficult. places show satellite imagery roads state government road layers . Finally, make complete need account areas NA’s within Forest Service land give 1 since likely wildnerness areas.","code":"library(sfnetworks) library(arcgis) library(purrr) library(tidygraph)  idaho <- AOI::aoi_get(stat = 'Idaho')  id_roads_sf <- arc_select(arc_open('https://gisportalp.itd.idaho.gov/xserver/rest/services/RH_GeneralService/MapServer/1/'))%>%   st_transform(3742)  ### this is because of an empty geometry; hopefully you won't have to deal with.... empty_geom <- id_roads_sf %>% st_geometry() %>% map(~is_empty(.x))  id_roads_sf$empty_geom <- unlist(empty_geom)  id_roads_sf <- id_roads_sf %>% filter(empty_geom == FALSE)  # you'll need to figure out how to get your usfs simple feature; here it was local for me.  usfs_roads <- read_sf('Z:/simple_features/roads/r1_rd_core.shp') %>% st_intersection(st_transform(idaho, st_crs(.)))%>%   st_transform(3742)  roads_together <- bind_rows(id_roads_sf%>% filter(SystemCode != 'FD'), usfs_roads) %>% st_as_sf() %>% st_cast('LINESTRING')  ########### Or bring in a clean version of the roads for your AOI ########  #roads_mt_id_clean <- read_sf('data/road_mt_id_fs.shp')  # get the mussel locations mussel_point <- mapedit::drawFeatures() %>% st_transform(crs = st_crs(usfs_roads))  # create a network and check for errors....   # set to conda env reticulate::use_condaenv(r'{C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3}')  arcpy <- reticulate::import('arcpy')  write_sf(roads_together, paste0(getwd(), '/data/together_roads.shp'))  arcpy$env$workspace = paste0(getwd(), '/data')  arcpy$CreateFileGDB_management(out_name = 'roads.gdb', out_folder_path = arcpy$env$workspace)  arcpy$FeatureToLine_management(in_features =  paste0(getwd(), '/data/together_roads.shp'), out_feature_class = 'roads.gdb/together_roads', cluster_tolerance = '5 Meters')  roads_together <- read_sf('data/roads.gdb', layer = 'together_roads') %>% st_cast(\"LINESTRING\")  # also convert to a crs that is good for north to south, etc. 3742 EPSG for Idaho UTM 12  net <- as_sfnetwork(roads_together, directed = FALSE) %>%   activate(\"edges\") %>%   mutate(weight = edge_length()) %>%   filter(!tidygraph::edge_is_multiple()) %>%   filter(!tidygraph::edge_is_loop()) # get the distances between the mussel_point and the nodes in the network  distances <- sfnetworks::st_network_cost(net, from = mussel_point, weights = 'weight')  # now get the 'from' in the network edged_start <- net %>% activate('edges') %>% pull(from)  # convert infinite to numeric net_final <- net %>%               activate('edges') %>%               mutate(new_weight = map(edged_start, ~as.numeric(if_else(is.infinite(distances[[.x]]), NA_real_, as.numeric(distances[[.x]])))))  # convert from meters to miles net_final_edges <- net_final %>% activate('edges') %>%                     mutate(new_weight = unlist(new_weight),                    new_weight = ifelse(is.infinite(new_weight), NA_real_, new_weight),                    new_weight_miles = as.numeric(new_weight*0.000621371)) %>%                     select(-new_weight) %>% st_as_sf() # adding huc12s and aggregating with a mean distance will make it easier for joining and not a lot of information lost  # now combined with HUCS to make easier.  huc12 <- read_sf('data/simple_features.gpkg', layer = 'huc12')  huc_list <- st_intersects(net_final_edges, st_transform(huc12, crs = st_crs(net_final_edges)))  huc_list <- map_vec(huc_list, ~ifelse(is.null(.x), NA, .x))  huc12s <- huc12[huc_list,]$huc12  # now add back to the network net_final_edges$huc12 <- huc12s  distance_by_huc <- net_final_edges %>% group_by(huc12) %>% summarise(mean_dist = mean(new_weight_miles, na.rm = TRUE)) %>%    ungroup() %>% st_as_sf() %>% st_drop_geometry() %>% select(huc12, mean_dist)  distance_by_huc <- distance_by_huc %>% mutate(   mussel_proximity = case_when(     mean_dist > 400 ~ 1,     mean_dist > 300 & mean_dist <= 400 ~ 2,     mean_dist > 200 & mean_dist <= 300 ~ 3,     mean_dist <= 200 ~ 4,      TRUE ~ NA_real_   ) )  # Need to get centroid of lakes and then associated HUC12s  lake_list <- st_centroid(waterbodies_idaho) %>% st_intersects(huc12)  lake_list <- map_vec(lake_list, ~ifelse(is.null(.x), NA, .x))  huc12s <- huc12[lake_list,]$huc12  waterbodies_idaho$huc12 <- huc12s  # we'll need to get COMIDs and HUC12 codes  # download from online https://www.sciencebase.gov/catalog/item/57eaa10fe4b09082500db04e huc_comid <- read_sf(r'{Z:\\Downloads\\HUC12_PU_COMIDs_CONUS\\HUC12_PU_COMIDs_CONUS.dbf}') %>% janitor::clean_names()  nhdplus_idaho <- nhdplus_idaho %>% left_join(huc_comid %>% select(comid, huc12))  # now join back with the waterbodies and nhdplus datasets  nhdplus_idaho <- nhdplus_idaho %>% left_join(distance_by_huc, by = 'huc12')  waterbodies_idaho <- waterbodies_idaho %>% left_join(distance_by_huc, by = 'huc12') ### bring in your own admin units layer fs_lands <- read_sf('Z:/fisheries/btbaseline/data/bt_baseline.gpkg', layer = 'admin_units') %>% st_transform(crs = 4326)  npcw_idph <- fs_lands %>% filter(FORESTNAME %in% c('Nez Perce-Clearwater National Forest','Idaho Panhandle National Forests')) %>%   st_make_valid() %>% st_union()  ### get for nhdplus wild_water <- nhdplus_idaho %>% st_intersects(npcw_idph)  wild_water <- map_vec(wild_water, ~ifelse(is.null(.x), NA, .x))  nhdplus_idaho$fs_land <- wild_water  ### now for waterbodies  wild_water <- waterbodies_idaho %>% st_intersects(npcw_idph)  wild_water <- map_vec(wild_water, ~ifelse(is.null(.x), NA, .x))  waterbodies_idaho$fs_land <- wild_water   ### bring it all together nhdplus_idaho_final_social <- nhdplus_idaho %>% mutate(mussel_proximity = if_else(is.na(mussel_proximity) & fs_land == 1, 1, mussel_proximity))  waterbodies_idaho_final_social <- waterbodies_idaho %>% mutate(mussel_proximity = if_else(is.na(mussel_proximity) & fs_land == 1, 1, mussel_proximity))  waterbodies_idaho_final_social %>%    st_intersection(idaho) %>%    write_sf('data/simple_features.gpkg', layer = 'waterbodies_idaho_final_social', delete_layer = T)  nhdplus_idaho_final_social  %>%    st_intersection(idaho) %>%    write_sf('data/simple_features.gpkg', layer = 'nhdplus_idaho_final_social', delete_layer = T)"},{"path":"https://github.com/soilwaterfish/aisrisk/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Josh Erickson. Author, maintainer.","code":""},{"path":"https://github.com/soilwaterfish/aisrisk/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Erickson J (2024). aisrisk: Model Risk Aquatic Invasive Species. R package version 0.1, https://soilwaterfish.github.io/aisrisk/.","code":"@Manual{,   title = {aisrisk: Model Risk for Aquatic Invasive Species},   author = {Josh Erickson},   year = {2024},   note = {R package version 0.1},   url = {https://soilwaterfish.github.io/aisrisk/}, }"},{"path":"https://github.com/soilwaterfish/aisrisk/DISCLAIMER.html","id":null,"dir":"","previous_headings":"","what":"Disclaimer","title":"Disclaimer","text":"information preliminary provisional subject revision. provided meet need timely best science. information received final approval U.S. Department Agriculture (USDA) provided condition neither USDA U.S. Government shall held liable damages resulting authorized unauthorized use information. Although software program used USDA, warranty, expressed implied, made USDA U.S. Government accuracy functioning program related program material shall fact distribution constitute warranty, responsibility assumed USDA connection therewith. software provided “.”","code":""},{"path":"https://github.com/soilwaterfish/aisrisk/index.html","id":"aisrisk","dir":"","previous_headings":"","what":"Model Risk for Aquatic Invasive Species","title":"Model Risk for Aquatic Invasive Species","text":"goal aisrisk provide repository workflows code used create Aquatic Invasive Species (AIS) invasion risk prioritization Idaho specifically Nez-Perce/Clearwater Idaho Panhandle National Forests. Currently heavy development.","code":""},{"path":"https://github.com/soilwaterfish/aisrisk/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Model Risk for Aquatic Invasive Species","text":"preliminary output accomplished vignettes.","code":""},{"path":"https://github.com/soilwaterfish/aisrisk/index.html","id":"disclaimer","dir":"","previous_headings":"","what":"Disclaimer","title":"Model Risk for Aquatic Invasive Species","text":"information preliminary provisional subject revision. provided meet need timely best science. information received final approval U.S. Department Agriculture (USDA) provided condition neither USDA U.S. Government shall held liable damages resulting authorized unauthorized use information. Although software program used USDA, warranty, expressed implied, made USDA U.S. Government accuracy functioning program related program material shall fact distribution constitute warranty, responsibility assumed USDA connection therewith. software provided “.”","code":""},{"path":"https://github.com/soilwaterfish/aisrisk/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 aisrisk authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""}]
